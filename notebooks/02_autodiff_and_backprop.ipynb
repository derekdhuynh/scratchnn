{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1b49b58e",
   "metadata": {},
   "source": [
    "# Automatic Differentiation and Backpropagation\n",
    "\n",
    "### Resources\n",
    "* [UBC autodiff lecture](https://www.cs.ubc.ca/~fwood/CS340/lectures/AD1.pdf)\n",
    "* [U of T autodiff slides](https://www.cs.toronto.edu/~rgrosse/courses/csc321_2018/slides/lec10.pdf)\n",
    "* [Leimao Blog post](https://leimao.github.io/article/Automatic-Differentiation/)\n",
    "* [Ari Seff video](https://www.youtube.com/watch?v=wG_nF1awSSY)\n",
    "* [UMass autodiff](https://people.cs.umass.edu/~domke/courses/sml2011/08autodiff_nnets.pdf)\n",
    "* [CS231n Backprop](https://cs231n.github.io/optimization-2/)\n",
    "* [Autodiff In Machine Learning: A Survey](https://arxiv.org/abs/1502.05767)\n",
    "* [CS229 Backprop](http://cs229.stanford.edu/notes2020spring/cs229-notes-deep_learning.pdf)\n",
    "* [Computation Graph](http://alexminnaar.com/2018/07/14/simple-computational-graph-engine.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5aacf8d",
   "metadata": {},
   "source": [
    "### Backpropagation and Autodiff\n",
    "\n",
    "One of the core aspects of all modern deep learning frameworks is the idea of differential programming, which is\n",
    "a paradigm that emphasizes being able to differentiate numeric programs using *automatic differentiation* \n",
    "(autodiff). This allows us to perform things like gradient-based optimization to fit the parameters of a neural\n",
    "network efficiently and easily.\n",
    "\n",
    "**Comparison of Differentiation Techniques**\n",
    "\n",
    "Like we learned in high school, there are two ways that we can differentiate a given function. The first is \n",
    "*numeric differentiation* where we use finite differences to approximate the value of the derivative at a certain\n",
    "value. The issue with this method is that it produces innacurate estimates as well as being very slow O(n) (need\n",
    "to compute this for each individual weight). Using very small values for $h$ can also lead\n",
    "to numerical stability problems.\n",
    "\n",
    "\\begin{equation}\n",
    "    f^\\prime(x) = \\frac{f(x+h) - f(x)}{h}\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "adefc464",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a5044ac4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "779.9373781153918"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Numeric differentiation\n",
    "def numeric_diff(func, x, epsilon=0.0001):\n",
    "    return (func(x+epsilon) - func(x)) / epsilon\n",
    "\n",
    "def exponential_func(x):\n",
    "    return np.exp(2*x) - x**3\n",
    "\n",
    "numeric_diff(exponential_func, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f16d8af8",
   "metadata": {},
   "source": [
    "We can also use our derivative rules to perform *symbolic differentiation*. This gives us an exact expression for\n",
    "the value of the derivative, however it can be slow and produce unneeded complexity in the resulting computation\n",
    "(this is called expression swell where the derivative of a function can become exponentially larger such as when \n",
    "applying the product rule). This problem is exacerbated in the context of neural networks where the derivative is\n",
    "computed w.r.t to many layers, making the expressions explode. The closed form solution it gives also is not\n",
    "advantageous as we are only concerned with obtaining a numerical value.\n",
    "\n",
    "\\begin{align}\n",
    "    f(x) &= e^{2x} - x^3\\\\\n",
    "    f^\\prime(x) &= 2e^{2x}-3x^2\n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "52c271ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "779.8575869854702\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7fe5c455fe50>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Symbolic differentiation\n",
    "def dx_exponential(x):\n",
    "    return 2*np.exp(2*x) - 3*x**2\n",
    "\n",
    "print(dx_exponential(3))\n",
    "\n",
    "x = np.linspace(-3, 3, 100)\n",
    "plt.plot(x, exponential_func(x), label='f')\n",
    "plt.plot(x, dx_exponential(x), label='f_prime')\n",
    "plt.title('Exponential Function and Derivative')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65a05512",
   "metadata": {},
   "source": [
    "## Autodiff and Why\n",
    "\n",
    "All these problems are fixed by using autodiff. Unlike symbolic differentiation which tries to find an expression\n",
    "for the function, autodiff just finds a numerical value. It uses the idea that a numeric program consists of a\n",
    "combination of some primitive operations which we know the derivative of. For the most part the elementary functions\n",
    "and operations like:\n",
    "* Binary arithmetic operations\n",
    "* Unary sign switches\n",
    "* Transcendental functions (log, exp, trig)\n",
    "\n",
    "<img src='./img/autodiff_ex.png' width='400'> </img>\n",
    "\n",
    "You can think of autodiff as a way of reinterpreting a program by augmenting the arithmetic computation with the\n",
    "computations of the derivatives.\n",
    "\n",
    "### Evaluation Trace\n",
    "We need to trace expressions for their primitive operations, and we can do this by breaking up an expression using\n",
    "a [Wengert List](https://www.cs.cmu.edu/~wcohen/10-605/assignments/2016-fall/drafts/autodiff.pdf). There are in\n",
    "general three categories of variables we need to consider in every expression for some function $f: R^n \\to R^m$:\n",
    "1. Input variables - $x_i$, for $i = 1, \\dots n$\n",
    "2. Intermediate variables - $v_i$ for $i = 1, \\dots l$\n",
    "3. Output variables - $y_{m-i}$, $i=m-1, \\dots 0$\n",
    "\n",
    "There are two main forms of autodiff, the first is forward mode and the second is reverse mode.\n",
    "\n",
    "For example, $f(x_1, x_2) = \\ln(x_1) + x_1x_2 - \\sin(x_2)$ converted to an evaluation trace would be:\n",
    "* $v_1 = \\ln(x_1)$\n",
    "* $v_2 = x_1 x_2$\n",
    "* $v_3 = \\sin(x_2)$\n",
    "* $v_4 = v_1 + v2$\n",
    "* $y = v_4 - v_3$\n",
    "\n",
    "\n",
    "### Forward-mode Autodiff\n",
    "Suppose we constructed the evaluation trace the same as above. We introduce new variables that are associated with\n",
    "the intermediate variables $v_i$, $\\dot{v_i}$ which are the derivatives. For example to determine the partial \n",
    "derivative of $x_1$ w.r.t $y$, we would use intermediate variables $\\dot{v_i} = \\frac{\\partial v_i}{\\partial x_1}$\n",
    "and likewise for $x_2$. We call the collection of all these derviative variables the \"tangent trace\".\n",
    "\n",
    "Then it is easy to see how we can perform the computation of the in the same evaluation pass as our evaluation \n",
    "trace. Suppose $x_1 = 2, x_2 = 5$. The tangent trace would be:\n",
    "* $\\dot{x_1} = 1$, $\\dot{x_2} = 0$, remember it is the derivative w.r.t $x_1$. We substitute these into the rest \n",
    "of the equations.\n",
    "* $\\dot{v_1} = \\frac{\\partial v_1 = \\partial \\ln{x_1}}{\\partial x_1} = \\frac{1}{v_1 }\\frac{\\partial x_1}{\\partial x_1} = \\frac{\\dot{x_1}}{v_1} $ --> notice how the necessary use of the chain rule nicely introduces our previous $\\dot{x_1}$. We can compute this right after we compute $v_1$.\n",
    "* $\\dot{v_2} = \\frac{\\partial \\dot{v_2} = \\partial x_1 x_2}{\\partial x_1}$, know we use product rule between\n",
    "$x_1$ and $x_2$, so we sub in the corresponding $\\dot{x_i} \\implies \\dot{v_2} = \\dot{x_1}x_2 + x_1 \\dot{x_2}$\n",
    "* $\\dot{v_3} = \\frac{\\partial v_3 = \\partial \\sin(x_2)}{\\partial x_1} = \\cos(x_2) \\dot{x_2}$\n",
    "* $\\dot{v_4} = \\frac{\\partial v_4 = \\partial v_1 + v_2}{\\partial x_1} = \\dot{v_2} + \\dot{v_1}$ --> another example how previous work efficiently allows us to compute the intermediate derivatives\n",
    "* $\\dot{v_5} = \\frac{\\partial v_5 = \\partial v_4 - v_5}{\\partial x_1} = \\dot{v_4} - \\dot{v_5}$.\n",
    "\n",
    "This gives us a single column of the the jacobian $\\mathbf{J}_f$, or simply the gradient matrix $\\nabla f$. We can\n",
    "obtain the full Jacobian by performing a tangent trace on all other input variables (just $x_2$ in this case).\n",
    "\n",
    "We can see that in forward mode autodiff, the runtime is remains in the same complexity class, with the constant \n",
    "overhead of having to compute the tangent trace. If we want the full Jacobian, the process would scale linearly\n",
    "$\\mathcal{O}(n)$ w.r.t to the number of input variables $n$. So we want to use forward mode auto diff if the number\n",
    "of output variables $m >> n$, especially functions $f: \\mathbb{R} \\to \\mathbb{R^m}$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1004f75",
   "metadata": {},
   "source": [
    "### Reverse-mode Autodiff\n",
    "Reverse-mode autodiff is a generalized version of the backpropagation algorithm and in contrast to forward mode\n",
    "autodiff it propagates the gradients backwards starting from the outputs.\n",
    "\n",
    "We do this by performing a forward trace, keeping track of the intermediate values and the dependencies, then\n",
    "starting from the outputs, we iteratively compute $\\bar{v_i} = \\frac{\\partial y_j}{\\partial v_i}$, which measures the\n",
    "sensitivity of the output when $v_i$ is perturbed. Backpropagation is the case where we have a single scalar\n",
    "output $y_j$.\n",
    "\n",
    "### Chain Rule From a Distance\n",
    "Suppose we have some arbitrarily nested function of some variable, which we will call $y = f^i(\\theta)$, where $f^i$\n",
    "represents $i$ functions being consecutively on $\\theta$. Then the chain rule simply tells us that $\\frac{\\partial y}{\\partial \\theta} = \\frac{\\partial f^{i}(\\theta)}{\\partial f^{i-1}(\\theta)} \\frac{\\partial f^{i-1}(\\theta)}{\\partial \\theta} = \\frac{\\partial f^{i}(\\theta)}{\\partial f^{i-1}(\\theta)} \\frac{\\partial f^{i-1}(\\theta)}{\\partial f^{i-2}} \\frac{\\partial f^{i-2}(\\theta)}{\\partial f^{i-3}} \\dots \\frac{\\partial f^1(\\theta)}{\\partial \\theta}$.\n",
    "\n",
    "In other words, if some variable $J$ depends on the parameters $\\theta_1 \\dots \\theta_p$ via the intermediate \n",
    "variables $g_1 \\dots g_k$ for all $\\theta_i$ (each parameter has a set of intermediate variables), then the contribution of a change in $\\theta_i$ in $J$ is:\n",
    "$$\n",
    "\\frac{\\partial J}{\\partial \\theta_i} = \\sum_{j=1}^{k} \\frac{\\partial J}{\\partial g_j} \\frac{\\partial g_j}{\\partial \\theta_i}\n",
    "$$\n",
    "\n",
    "Imagine that this arbitrary composition of functions, is instead the composition of matrix multiplies, adds, and\n",
    "activation functions with each operation being a single $f^i$. Then we have a way of identifying $\\frac{\\partial y}{\\partial \\theta}$ to measure how much changing a parameter of a particular changes the value of the loss function.\n",
    "\n",
    "\n",
    "Coming back to the same example as the forward case, we can see how this process works:\n",
    "* $\\bar{y} = \\frac{\\partial y}{\\partial y} = 1$\n",
    "* $\\bar{v_4} = \\bar{y} \\frac{\\partial y}{\\partial v_4} = \\frac{\\partial v_4 - v_3}{\\partial v_4} = \\frac{\\partial v_4}{\\partial v_4} - \\frac{\\partial v_3}{\\partial v_4} = 1 - 0 = 1$, notice how after expanding the expression, we\n",
    "find that it is quite obvious that by going in reverse topological order, $y$ will have clear and easily computable\n",
    "dependence on $v_4$ since $y = v_4 - v_3$. Then by gradient as linear operator, we see that $v_4$ and $v_3$ have\n",
    "no interdependence and thus the gradient w.r.t $v_4$ is 0.\n",
    "* $\\bar{v_3} = \\frac{\\partial y}{\\partial v_3} = \\frac{\\partial y}{\\partial v_4} \\frac{\\partial y}{\\partial v_3} = \\bar{v_4} * -1 = -1$, again same as above as $v_3$ is directly present in $y$.\n",
    "* $\\bar{v_2} = \\frac{\\partial y}{\\partial v_2} = \\frac{\\partial y}{\\partial v_4} \\frac{\\partial v_4}{\\partial v_2} = \\bar{v_4} \\frac{\\partial v_1 + v_2}{\\partial v_2} = 1 * 1 = 1 $\n",
    "* $\\bar{v_1} = \\frac{\\partial y}{\\partial v_1} = \\frac{\\partial y}{\\partial y} \\frac{\\partial y}{ \\partial v_4} \\frac{\\partial v_4}{\\partial v_1} = \\bar{y} \\bar{v_4} \\frac{\\partial v_4}{\\partial v_1} = 1 * 1 * 1 = 1$\n",
    "\n",
    "Now for computing the derivatives w.r.t to the inputs, we'll have to do this in incremental steps, split up by the\n",
    "occurences of addition or subtraction of terms that depend on the inputs (since deriv is linear).\n",
    "* $\\bar{x_2} = \\frac{\\partial y}{\\partial x_1} = \\bar{v_2} \\frac{\\partial v_2}{\\partial x_2} = 1 * 2 = 2$\n",
    "* $\\bar{x_2} = \\bar{x_2} + \\bar{v_3} \\frac{\\partial v_3}{\\partial x_2} = 2 - 1 * \\cos(5) = 1.716$\n",
    "* $\\bar{x_1} = \\frac{\\partial y}{\\partial x_1} = \\bar{v_1} \\frac{\\partial v_1}{\\partial x_1} = 1 * \\frac{1}{x_1} = 0.5$\n",
    "* $\\bar{x_1} = \\bar{x_1} + \\bar{v_2} \\frac{\\partial v_2}{\\partial x_1} = 0.5 + 1 * x_2 = 5.5$\n",
    "\n",
    "\n",
    "### Backprop Implementation Notes\n",
    "* Notice in our example that gradients were propagated through the intermediates, and the total gradient of a certain variable could be obtained by using the chain rule.\n",
    "* Multiplying by the gradient of the closest adjacent child nodes (parenthood going from left to right, so node directly to left of another is considered the parent), this would implicitly include the gradient of dependent variables deeper in the hierarchy (i.e $\\frac{\\partial y}{\\partial v_3}$ implicitly includes the gradient of all resultant  dependent primitive expressions $v_i, i > 3$).\n",
    "* This way we only look at upstream gradients ($\\bar{v_i}$'s) that have a direct dependency on the variable of interest.\n",
    "\n",
    "The only complication to just spamming the chain rule is when gradient aggregating operations are involved, such as addition, subtraction, scalar multiplication. In this case, we will need to incrementally deal with these operations such as in the computation os $\\bar{x_1}$.\n",
    "\n",
    "### Computational Graph and Backprop\n",
    "\n",
    "One thing when implementing autodiff and backprop is that you will need a data structure to store the intermediate\n",
    "representations of each individual computation. The most common way to do this is by constructing a computational\n",
    "graph where the computations are broken up into the nodes of the directed graph and feed into each other front\n",
    "to back (directed acyclic graph or DAG). It will need to be bi-directional, as at each new node is an operation that has associated operands which feed into the node and will be used to compute gradients.\n",
    "\n",
    "Below is a very simple example of breaking up a single function into a computational graph:\n",
    "\n",
    "<img src='./img/computation_graph_ex.png'> </img>\n",
    "\n",
    "This simple example is exactly how the *backpropagation* algorithm works, by first computing all the outputs of\n",
    "the network, storing each of them on the graph and then perform a backward pass to compute \n",
    "$\\frac{\\partial J}{\\partial w}$ by computing the easy primitive derivatives and using the chain rule to propagate\n",
    "the gradients throughout the weights in each layer.\n",
    "\n",
    "When we calculated the derivative of f w.r.t y/x and used the chain rule the following terminology can be\n",
    "used:\n",
    "\n",
    "\\begin{align}\n",
    "\\frac{\\partial f}{\\partial x} &= \\frac{\\partial f}{\\partial v} \\frac{\\partial v}{\\partial x}\\\\\n",
    "\\frac{\\partial f}{\\partial x} &= \\text{the downstream gradient} \\\\\n",
    "\\frac{\\partial f}{\\partial v} &= \\text{the upstream gradient} \\\\\n",
    "\\frac{\\partial v}{\\partial x} &= \\text{the local gradient}\n",
    "\\end{align}\n",
    "\n",
    "The **upstream gradient** being how the current computation affects the one directly ahead of it, the **downstream** being\n",
    "the how the computation before the current one affects the current one and the **local gradient** being the \n",
    "computation currently examined (the link for the output and the input).\n",
    "\n",
    "The biggest advantage of this formalism is how modular it is, a single node need not care about what goes into it\n",
    "or what goes out of it. We only need to focus on local processes which ultimately lead us to a final, global\n",
    "value.\n",
    "\n",
    "**LogSumExp Trick**\n",
    "\n",
    "It is common when implementing a neural network that you run into numerical stability issues involving underflows (python cannot\n",
    "interpret a sufficiently small floating point so it thinks it is 0) and overflow (inf and nan).This is especially apparent with things\n",
    "like the softmax function where the sum of the exponential functions can become 0 with sufficiently small numbers (large negative \n",
    "numbers, becomes nan). To combat this we use the LogSumExp trick which is a technique to avoid these numerical stability problems.\n",
    "Take the softmax function:\n",
    "\n",
    "\\begin{equation}\n",
    "    \\frac{\\exp(x_m)}{\\sum^n_{i=1} \\exp(x_i)} = 1\n",
    "\\end{equation}\n",
    "\n",
    "We want to take the log of this function (makes taking derivatives easier as products turn into addition and subtraction). First let's\n",
    "rewrite it:\n",
    "\\begin{align}\n",
    "    \\exp(x_m) &= \\sum^n_{i=1} \\exp(x_i) \\\\\n",
    "    x_m &= \\log\\sum^n_{i=1} \\exp(x_i) \\qquad \\text{take the log}\\\\\n",
    "    0 &= x_m - \\log\\sum^n_{i=1} \\exp(x_i) \\\\\n",
    "    1 &= \\exp \\left( x_m - \\log\\sum^n_{i=1} \\exp(x_i) \\right) \\qquad \\text{exp both sides}\\\\\n",
    "\\end{align}\n",
    "\n",
    "So we can rewrite our softmax function, normalizing logits using the expression above here we can see our LogSumExp operation \n",
    "$ \\log\\sum^n_{i=1} \\exp(x_i)$. Now we need some way to \"get rid\" of that nasty $\\exp(x_i$. To do this consider the following derivation \n",
    "of the LSE operation:\n",
    "\n",
    "\\begin{align}\n",
    "    y &= \\log\\sum^n_{i=1} \\exp(x_i) \\\\\n",
    "    \\exp(y) &= \\sum^n_{i=1} \\exp(x_i) \\\\\n",
    "    \\exp(y) &= \\exp(c) \\sum^n_{i=1} \\exp(x_i - c) \\qquad \\text{factor out c} \\\\\n",
    "    y &= c + \\log \\sum^n_{i=1} \\exp(x_i - c) \\qquad \\text{take log} \\\\\n",
    "\\end{align}\n",
    "\n",
    "This means we can arbitrarily shift the values of the exponentiation by some constant $c$ which can ensure that there will be no\n",
    "over or underflow. We usually use the maximum value of the $x_i$'s so that the largest value of the exponentiation is 1 (since shifting\n",
    "the numbers by the max makes them all $\\leq 0$). We then shift them back to their original positions by adding $c$ back.\n",
    "\n",
    "# Backprop and Neural Networks\n",
    "* https://web.stanford.edu/class/archive/cs/cs224n/cs224n.1184/readings/gradient-notes.pdf\n",
    "\n",
    "The multilayer perceptron is the most common type of neural network and is employed mainly due to its power as a\n",
    "[universal function approximator](https://ai.stackexchange.com/questions/13317/where-can-i-find-the-proof-of-the-universal-approximation-theorem). Commonly, we train a neural network model via an optimization problem involving a set of parameters $\\theta$, with the goal of choosing $\\theta$ such that $h_\\theta(\\mathbf{x})$ is a good fit for $\\mathbf{y}$ (for some definition of \"good\", which is usually some loss function).\n",
    "\n",
    "Unfortunately, with the great ability to produce mappings between the spaces of $x$ and $y$, it comes with the downside of is that the [empirical risk](https://ee104.stanford.edu/lectures/erm.pdf) (the average loss over some sample of data points) is almost always non-convex (i.e it has many valleys and peaks, we can get stuck in local minima as we traverse the loss landscape).\n",
    "\n",
    "Backprop concerns itself with the question of which procedure should be performed in order to efficiently adjust $\\theta$ such that we nicely reduce the empirical risk. We do so by computing gradients of the empirical risk $\\mathcal{L}(\\hat{y}, y) \\in \\mathbb{R}$ w.r.t to $\\theta_j \\in \\mathbb{R}^{d}$\n",
    "\n",
    "## Gradient of Scalar Function w.r.t Matrix (connected by vector intermediate)\n",
    "\n",
    "We know that normally, when we have $z = \\mathbf{W}x$, taking $\\frac{\\partial z}{\\partial W}$ results in a rank-3\n",
    "tensor, that is $m \\times m \\times n$, where $W \\in \\mathbb{R}^{m\\times n}$ and $x \\in \\mathbb{R}^n$, causing $z \\in \\mathbb{R}^m$. However, when we make gradient updates via gradient descent, we want to do it easily, and have the\n",
    "shapes of the gradients match the shapes of the weight matrices.\n",
    "\n",
    "In the ML case, we will have $z$ give us a direct relationship between our loss function $\\mathcal{L}$ and the \n",
    "weight matrix $\\mathbf{W}$, and we use the proposition in backprop and techniques from auto-diff to compute $\\frac{\\partial \\mathcal{L}}{\\partial W}$.\n",
    "\n",
    "Suppose we know that the adjoint for $z$, that is $\\bar{z} = \\frac{\\partial \\mathcal{L}}{\\partial z}$. This we know is simply a vector (which by our modified convention, is a row vector, $\\bar{z} \\in \\mathbb{R}^{1 \\times n}$).\n",
    "\n",
    "Then, by the chain rule $\\frac{\\partial \\mathcal{L}}{\\partial W} = \\frac{\\partial \\mathcal{L}}{\\partial z} \\frac{\\partial z}{\\partial W}$. We derive this by working up from a single weight.\n",
    "\n",
    "It is useful to instead consider the derivative of $z$ w.r.t to a single weight $W_{ij}$, which simply turns out to be a vector. Since $z_i = W_i \\cdot x$, then $W_{ij}$ will only be present in the term $W_{ij}x_j$, (which is only is only in the i-th row and j-th column) and so taking the derivative of $f$ w.r.t $A_{ij}$ we get:\n",
    "\n",
    "$\\frac{\\partial f}{\\partial A_{ij}} =\n",
    "\\begin{bmatrix}\n",
    "0 \\\\\n",
    "\\vdots \\\\\n",
    "0 \\\\\n",
    "x_j \\\\\n",
    "0 \\\\\n",
    "\\vdots \\\\\n",
    "0\n",
    "\\end{bmatrix}\n",
    "\\in \\mathbb{R}^{M}$, with again the $i$-th element being $x_j$\n",
    "\n",
    "So then we have $\\bar{W_{ij}} = \\frac{\\partial \\mathcal{L}}{\\partial z} \\frac{\\partial z}{\\partial W_{ij}} = \\bar{z}_i x_j $,\n",
    "since this is which is a row vector times a column vector, producing a scalar from their dot product. Since every element in $\\frac{\\partial z}{\\partial W_{ij}}$ is $0$ other than the $i$-th element, we get our result. Then we want the matrix that contains $\\bar{z}_i x_j$ in entry $(i, j)$, which is the matrix that is formed by the outer \n",
    "product: $\\bar{W} = \\frac{\\partial \\mathcal{L}}{\\partial W} = \\frac{\\partial \\mathcal{L}}{\\partial z} \\frac{\\partial z}{\\partial W} = \\bar{z} \\otimes x$ (assume they are both row vectors by convention).\n",
    "\n",
    "So by doing the derivation this way and somewhat abusing the gradient shape notation, we avoid having to deal with the rank-3 tensor produced by computing the gradient of the weight matrix.\n",
    "\n",
    "### Weight Initialization\n",
    "* https://proceedings.mlr.press/v9/glorot10a/glorot10a.pdf\n",
    "* https://arxiv.org/pdf/1502.01852.pdf - He normal\n",
    "* https://stackoverflow.com/questions/42670274/how-to-calculate-fan-in-and-fan-out-in-xavier-initialization-for-neural-networks"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "ml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
